{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Import the [`electrocardiograms.csv`](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv) dataset and display its first 5 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0  0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1  1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2  0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3  0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4  0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "\n",
       "        x_8       x_9      x_10  ...     x_179     x_180     x_181  x_182  \\\n",
       "0  0.413858  0.426966  0.485019  ...  0.000000  0.000000  0.000000    0.0   \n",
       "1  0.346429  0.314286  0.305357  ...  0.000000  0.000000  0.000000    0.0   \n",
       "2  0.656613  0.421114  0.288863  ...  0.294664  0.295824  0.301624    0.0   \n",
       "3  0.177019  0.270186  0.313665  ...  0.000000  0.000000  0.000000    0.0   \n",
       "4  0.108541  0.145907  0.192171  ...  0.000000  0.000000  0.000000    0.0   \n",
       "\n",
       "   x_183  x_184  x_185  x_186  x_187  target  \n",
       "0    0.0    0.0    0.0    0.0    0.0       1  \n",
       "1    0.0    0.0    0.0    0.0    0.0       1  \n",
       "2    0.0    0.0    0.0    0.0    0.0       1  \n",
       "3    0.0    0.0    0.0    0.0    0.0       1  \n",
       "4    0.0    0.0    0.0    0.0    0.0       1  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/electrocardiograms.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Each obervation of the dataset is a numerically represented heartbeat, taken from a patient's electrocardiogram (ECG). The target is binary and defines whether the heartbeat is at risk of cardiovascular disease [1] or not [0]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Plot an observation of each target class to get a visual idea of what the numbers represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá How many observations of at-risk heartbeats are there? Save your answer as `at_risk_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_risk_count = len(df[df.target == 1])\n",
    "at_risk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá How many observations of healthy heartbeats are there? Save your answer as `healthy_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_count = len(df[df.target == 0])\n",
    "healthy_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è In certain cases, the class balance is representative of the true class distribution. This is the case here: the vast majority of people actually have healthy hearts. In such case, we preserve the class distribution inform the model on the reality, and adapt our modelling approach accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "tests/test_class_balance.py::TestClass_balance::test_at_risk_count \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_class_balance.py::TestClass_balance::test_healthy_count \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/class_balance.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed class_balance step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('class_balance',\n",
    "                         healthy = healthy_count,\n",
    "                         at_risk = at_risk_count\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Your task is to flag heartbeats that are at risk of cardiovascular diseases.\n",
    "\n",
    "üëá Let's start by investigating the performance of a `LogisticRegression` on that task. Use cross validation to evaluate the model on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X=df.drop(columns=[\"target\"])\n",
    "y=df[\"target\"]\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=5, \n",
    "                            scoring=['precision',\n",
    "                                     'recall', \n",
    "                                     'accuracy',\n",
    "                                     'f1']\n",
    "                           )\n",
    "cv_results = pd.DataFrame(cv_results) # Cross validation output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the model's ratio of correct predictions? Save your answer under variable name `correct_pred_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391771019677997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = cv_results.test_accuracy\n",
    "correct_pred_ratio = accuracy.mean()\n",
    "correct_pred_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What percentage of at-risk heartbeats is the model able to flag? Save your answer under variable name `flag_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3300942608280635"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = cv_results.test_recall\n",
    "flag_ratio = recall.mean()\n",
    "flag_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì When the model signals an at-risk heartbeat, how often is it correct? Save your answer under variable name `correct_detection_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867386740061804"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = cv_results.test_precision\n",
    "correct_detection_ratio=precision.mean()\n",
    "correct_detection_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms?  Save your answer under variable name `aggregated_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44482198050033483"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1= cv_results.test_f1\n",
    "aggregated_metric = F1.mean()\n",
    "aggregated_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è By observing the different metrics, you should see that accuracy is deceiving. To understand what is going on, we can observe a breakdown of the model's predictions in a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_accuracy \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_f1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_recall \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.19s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/logistic_regression_evaluation.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed logistic_regression_evaluation step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logistic_regression_evaluation',\n",
    "                         accuracy = correct_pred_ratio,\n",
    "                         recall = flag_ratio,\n",
    "                         precision = correct_detection_ratio,\n",
    "                         f1 = aggregated_metric\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Using `plot_confusion_matrix` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)),  visualize the predictions breakdown of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Hints</summary>\n",
    "\n",
    "- `plot_confusion_matrix` takes as input a **trained model** and **test data**\n",
    "    \n",
    "- You'll need to go back to the **Holdout method!** You can use Sklearn's `train_test_split()` ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
    "    \n",
    "- Look into the `normalize` parameter\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2e0b69eeb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(LogisticRegression(max_iter = 1000).fit(X_train, y_train), X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è The confusion matrix should show that the model is influenced by the class imbalance: it predicts heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a high accuracy. However, it causes it to miss out on many at risk heartbeats: it has a bad recall.\n",
    "\n",
    "üëâ This model is therefore poor at the task of **flagging at-risk observations**.\n",
    "\n",
    "‚ö†Ô∏è Don't be fooled by the accuracy and look at the metric that corresponds to your task! ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Would a default KNN classifier perform better at the task of flagging at-risk observations?\n",
    "\n",
    "Save the you answer under `best_model` as \"KNN\" or \"LogisticRegression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3300942608280635, 0.8577210356759336)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "cv_results_log = cross_validate(LogisticRegression(max_iter = 1000), X, y, cv=5, \n",
    "                            scoring=['precision',\n",
    "                                     'recall', \n",
    "                                     'accuracy',\n",
    "                                     'f1']\n",
    "                           )\n",
    "recall_log = pd.DataFrame(cv_results_log).test_recall.mean() # Cross validation output\n",
    "\n",
    "cv_results_knn = cross_validate(KNeighborsClassifier(n_neighbors=5), X, y, cv=5, \n",
    "                            scoring=['precision',\n",
    "                                     'recall', \n",
    "                                     'accuracy',\n",
    "                                     'f1']\n",
    "                           )\n",
    "recall_knn = pd.DataFrame(cv_results_knn).test_recall.mean()\n",
    "\n",
    "recall_log, recall_knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"KNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è The KNN classifier should have a much higher recall than the LogisticRegression and therefore is better suited for the task.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_best_model.py::TestBest_model::test_best_model \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/best_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed best_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('best_model',\n",
    "                         model = best_model,\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the KNN model has the best recall, let's check out its performance accross all the other classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Print out a `classification_report` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)) of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> üí° Hint  </summary>\n",
    "    \n",
    "You'll need to pass model predictions to `classification_report`. Sklearn's `cross_val_predict` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)) might help üòâ\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18117\n",
      "           1       0.94      0.86      0.90      1448\n",
      "\n",
      "    accuracy                           0.99     19565\n",
      "   macro avg       0.96      0.93      0.94     19565\n",
      "weighted avg       0.99      0.99      0.99     19565\n",
      "\n",
      "KNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "y_pred = cross_val_predict(knn, X, y, cv=5)\n",
    "\n",
    "print(classification_report(y,y_pred))\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Looking at the classification report, what is the model's ratio of correctly predicted at-risk heartbeats? Save your answer as a float under `correct_atrisk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_atrisk_predictions = 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_precision.py::TestPrecision::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/precision.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed precision step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('precision',\n",
    "                         precision = correct_atrisk_predictions,\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ A patient comes to you for a second opinion on what he was told may be an at risk heartbeat.  Download its data [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_new_patient.csv).\n",
    "\n",
    "\n",
    "‚ùì According to your optimal model, is he at risk or not?  \n",
    "\n",
    "Save the prediction of your model under variable name `prediction` as \"at risk\" or \"healthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_1      0.904762\n",
       "x_2      0.993197\n",
       "x_3      1.000000\n",
       "x_4      0.956916\n",
       "x_5      0.902494\n",
       "           ...   \n",
       "x_183    0.000000\n",
       "x_184    0.000000\n",
       "x_185    0.000000\n",
       "x_186    0.000000\n",
       "x_187    0.000000\n",
       "Name: 0, Length: 187, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/ML_Electrocardiograms_new_patient.csv\")\n",
    "\n",
    "X_1 = df1.iloc[0]\n",
    "X_1 = pd.DataFrame(X_1, )\n",
    "\n",
    "len(X), len(X_1), len(y), len(y_pred)\n",
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "prediction = knn.fit(X,y).predict(df1)[0]\n",
    "X.shape, y.shape, df1.shape, prediction\n",
    "prediction = \"at risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_prediction.py::TestPrediction::test_prediction_at_risk \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('prediction',\n",
    "                         prediction = prediction\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
