{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will compare the effects of Loss functions on a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Import the data from the attached csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Glazing Area</th>\n",
       "      <th>Average Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>19.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "0                    0.98         514.5      294.0     110.25             7.0   \n",
       "1                    0.98         514.5      294.0     110.25             7.0   \n",
       "2                    0.98         514.5      294.0     110.25             7.0   \n",
       "3                    0.98         514.5      294.0     110.25             7.0   \n",
       "4                    0.90         563.5      318.5     122.50             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763                  0.64         784.0      343.0     220.50             3.5   \n",
       "764                  0.62         808.5      367.5     220.50             3.5   \n",
       "765                  0.62         808.5      367.5     220.50             3.5   \n",
       "766                  0.62         808.5      367.5     220.50             3.5   \n",
       "767                  0.62         808.5      367.5     220.50             3.5   \n",
       "\n",
       "     Glazing Area  Average Temperature  \n",
       "0             0.0               18.440  \n",
       "1             0.0               18.440  \n",
       "2             0.0               18.440  \n",
       "3             0.0               18.440  \n",
       "4             0.0               24.560  \n",
       "..            ...                  ...  \n",
       "763           0.4               19.640  \n",
       "764           0.4               16.710  \n",
       "765           0.4               16.775  \n",
       "766           0.4               16.545  \n",
       "767           0.4               16.335  \n",
       "\n",
       "[768 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Your task is to predict the average temperature inside a greenhouse based on its design. Your temperature predictions will help you select the appropriate greenhouse design for each plant, based on their climatic needs. \n",
    "\n",
    "üåø You know that plants can handle small temperature variations, but are exponentially more sensitive as the temperature variations increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Theoretically, which Loss function would you train your model on to limit the risk of killing plants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> üÜò Answer </summary>\n",
    "    \n",
    "By theory, you would use a Mean Square Error (MSE) Loss function. It would penalize outlier predictions and prevent your model from committing large errors. This would ensure smaller temperature variations and a lower risk for plants.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "In order to penalize outliers, we use MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Glazing Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "0                1.000000      0.000000   0.285714   0.000000             1.0   \n",
       "1                1.000000      0.000000   0.285714   0.000000             1.0   \n",
       "2                1.000000      0.000000   0.285714   0.000000             1.0   \n",
       "3                1.000000      0.000000   0.285714   0.000000             1.0   \n",
       "4                0.777778      0.166667   0.428571   0.111111             1.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763              0.055556      0.916667   0.571429   1.000000             0.0   \n",
       "764              0.000000      1.000000   0.714286   1.000000             0.0   \n",
       "765              0.000000      1.000000   0.714286   1.000000             0.0   \n",
       "766              0.000000      1.000000   0.714286   1.000000             0.0   \n",
       "767              0.000000      1.000000   0.714286   1.000000             0.0   \n",
       "\n",
       "     Glazing Area  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "763           1.0  \n",
       "764           1.0  \n",
       "765           1.0  \n",
       "766           1.0  \n",
       "767           1.0  \n",
       "\n",
       "[768 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features are numercial so we can scale them\n",
    "\n",
    "X = df.drop(columns = \"Average Temperature\")\n",
    "y = df[\"Average Temperature\"]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "mmscaler.fit(X)\n",
    "X = mmscaler.transform(X)\n",
    "X = pd.DataFrame(data = X, columns = df.columns[:-1])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to verify the theory by evaluating models optimized on different Loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares (MSE) Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá **10-Fold Cross-validate** a Linear Regression model optimized by **Stochastic Gradient Descent** (SGD) on a **Least Squares Loss** (MSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/cherif/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_max_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-9.287883</td>\n",
       "      <td>0.774477</td>\n",
       "      <td>-3.387399</td>\n",
       "      <td>-18.784843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>-9.121657</td>\n",
       "      <td>0.899754</td>\n",
       "      <td>-2.026848</td>\n",
       "      <td>-6.927465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>-9.496657</td>\n",
       "      <td>0.884832</td>\n",
       "      <td>-2.388593</td>\n",
       "      <td>-10.089618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>-9.811958</td>\n",
       "      <td>0.874554</td>\n",
       "      <td>-2.544204</td>\n",
       "      <td>-10.658519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-9.387168</td>\n",
       "      <td>0.925773</td>\n",
       "      <td>-1.820095</td>\n",
       "      <td>-6.452464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-9.127379</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>-2.261665</td>\n",
       "      <td>-10.154525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-9.033465</td>\n",
       "      <td>0.924115</td>\n",
       "      <td>-1.881864</td>\n",
       "      <td>-6.980851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>-9.386187</td>\n",
       "      <td>0.913028</td>\n",
       "      <td>-2.236755</td>\n",
       "      <td>-9.582432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>-8.913273</td>\n",
       "      <td>0.891719</td>\n",
       "      <td>-2.246383</td>\n",
       "      <td>-10.006127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-8.273607</td>\n",
       "      <td>0.934118</td>\n",
       "      <td>-1.871370</td>\n",
       "      <td>-6.408185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_max_error   test_r2  \\\n",
       "0  0.006735    0.001158       -9.287883  0.774477   \n",
       "1  0.006432    0.001068       -9.121657  0.899754   \n",
       "2  0.004071    0.000972       -9.496657  0.884832   \n",
       "3  0.004825    0.001043       -9.811958  0.874554   \n",
       "4  0.006499    0.000938       -9.387168  0.925773   \n",
       "5  0.006155    0.000991       -9.127379  0.892308   \n",
       "6  0.006832    0.000997       -9.033465  0.924115   \n",
       "7  0.005970    0.000989       -9.386187  0.913028   \n",
       "8  0.010452    0.001416       -8.913273  0.891719   \n",
       "9  0.005421    0.001052       -8.273607  0.934118   \n",
       "\n",
       "   test_neg_mean_absolute_error  test_neg_mean_squared_error  \n",
       "0                     -3.387399                   -18.784843  \n",
       "1                     -2.026848                    -6.927465  \n",
       "2                     -2.388593                   -10.089618  \n",
       "3                     -2.544204                   -10.658519  \n",
       "4                     -1.820095                    -6.452464  \n",
       "5                     -2.261665                   -10.154525  \n",
       "6                     -1.881864                    -6.980851  \n",
       "7                     -2.236755                    -9.582432  \n",
       "8                     -2.246383                   -10.006127  \n",
       "9                     -1.871370                    -6.408185  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr = SGDRegressor(loss='squared_loss') # OLS solved by SGD\n",
    "\n",
    "cv = cross_validate(sgdr, X, y, cv=10, scoring=['max_error',\n",
    "                                                'r2', \n",
    "                                                'neg_mean_absolute_error',\n",
    "                                                'neg_mean_squared_error'])\n",
    "cv = pd.DataFrame(cv)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Compute \n",
    "- the mean cross validated R2 score `r2`\n",
    "- the single biggest prediction error in ¬∞C of all your folds `max_error`?\n",
    "\n",
    "(Tips: `max_error` is an accepted scoring metrics in sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914679727710334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = cv['test_r2'].mean()\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.811957549244884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_error = abs(cv['test_max_error'].min())\n",
    "max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE) Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we optimize our model on the MAE instead?\n",
    "\n",
    "üëá **10-Fold Cross-validate** a Linear Regression model optimized by **Stochastic Gradient Descent** (SGD) on a **MAE** Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° Hints</summary>\n",
    "\n",
    "- MAE loss cannot be directly specified in `SGDRegressor`. It must be engineered by adjusting the right parameters\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_max_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-11.482624</td>\n",
       "      <td>0.725709</td>\n",
       "      <td>-3.720256</td>\n",
       "      <td>-22.846952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>-9.990904</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>-2.002703</td>\n",
       "      <td>-9.247606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>-10.421739</td>\n",
       "      <td>0.867641</td>\n",
       "      <td>-2.265463</td>\n",
       "      <td>-11.595651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>-10.818016</td>\n",
       "      <td>0.844125</td>\n",
       "      <td>-2.594048</td>\n",
       "      <td>-13.243959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>-11.209622</td>\n",
       "      <td>0.905039</td>\n",
       "      <td>-1.943613</td>\n",
       "      <td>-8.254910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>-11.242505</td>\n",
       "      <td>0.855285</td>\n",
       "      <td>-2.593103</td>\n",
       "      <td>-13.645546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>-10.741845</td>\n",
       "      <td>0.912465</td>\n",
       "      <td>-1.989929</td>\n",
       "      <td>-8.052623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>-12.029915</td>\n",
       "      <td>0.870410</td>\n",
       "      <td>-2.472264</td>\n",
       "      <td>-14.277961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>-11.431069</td>\n",
       "      <td>0.867793</td>\n",
       "      <td>-2.430876</td>\n",
       "      <td>-12.217146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>-10.888683</td>\n",
       "      <td>0.923596</td>\n",
       "      <td>-1.882536</td>\n",
       "      <td>-7.431707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_max_error   test_r2  \\\n",
       "0  0.015713    0.003752      -11.482624  0.725709   \n",
       "1  0.012502    0.003332       -9.990904  0.866180   \n",
       "2  0.011593    0.003315      -10.421739  0.867641   \n",
       "3  0.012039    0.003111      -10.818016  0.844125   \n",
       "4  0.011354    0.002953      -11.209622  0.905039   \n",
       "5  0.010206    0.002965      -11.242505  0.855285   \n",
       "6  0.011221    0.002915      -10.741845  0.912465   \n",
       "7  0.011393    0.003247      -12.029915  0.870410   \n",
       "8  0.011392    0.003482      -11.431069  0.867793   \n",
       "9  0.011527    0.003185      -10.888683  0.923596   \n",
       "\n",
       "   test_neg_mean_absolute_error  test_neg_mean_squared_error  \n",
       "0                     -3.720256                   -22.846952  \n",
       "1                     -2.002703                    -9.247606  \n",
       "2                     -2.265463                   -11.595651  \n",
       "3                     -2.594048                   -13.243959  \n",
       "4                     -1.943613                    -8.254910  \n",
       "5                     -2.593103                   -13.645546  \n",
       "6                     -1.989929                    -8.052623  \n",
       "7                     -2.472264                   -14.277961  \n",
       "8                     -2.430876                   -12.217146  \n",
       "9                     -1.882536                    -7.431707  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdrmae = SGDRegressor(loss=\"epsilon_insensitive\", epsilon = 0) \n",
    "\n",
    "cvmae = cross_validate(sgdrmae, X, y, cv=10, scoring=['max_error',\n",
    "                                                'r2', \n",
    "                                                'neg_mean_absolute_error',\n",
    "                                                'neg_mean_squared_error'])\n",
    "cvmae = pd.DataFrame(cvmae)\n",
    "cvmae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Compute \n",
    "- the mean cross validated R2 score `r2_mae`\n",
    "- the single biggest prediction error of all your folds `max_error_mae`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8638242127057282, 12.029914987639422)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_mae = cvmae['test_r2'].mean()\n",
    "\n",
    "max_error_mae = abs(cvmae['test_max_error'].min())\n",
    "\n",
    "r2_mae, max_error_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìWhich of the models you evaluated seems the most appropriate for your task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> üÜòAnswer </summary>\n",
    "    \n",
    "Although mean cross-validated r2 scores are approximately similar between the two models, the one optimized on a MAE has more chance to make larger mistakes from time to time, increasing risk of killing plants!\n",
    "\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/cherif/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/cherif/code/cherifbenham/data-challenges/05-ML/04-Under-the-hood/01-Loss-Functions\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "tests/test_loss_functions.py::TestLossFunctions::test_max_error_order \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_loss_functions.py::TestLossFunctions::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m          [ 66%]\u001b[0m\n",
      "tests/test_loss_functions.py::TestLossFunctions::test_r2_mae \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.16s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/loss_functions.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed loss_functions step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('loss_functions',\n",
    "    r2 = r2,\n",
    "    r2_mae = r2_mae,\n",
    "    max_error = max_error,\n",
    "    max_error_mae = max_error_mae,                     \n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
